"""
Analyse de Performances Serveur - Stage OPTIMAL
Auteur: Emma
Description: Analyse compl√®te des m√©triques CPU, M√©moire, R√©seau et Temp√©rature
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

# Configuration de l'affichage
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("=" * 80)
print("üñ•Ô∏è  ANALYSE DE PERFORMANCES SERVEUR - OPTIMAL")
print("=" * 80)
print()

# ============================================================================
# 1. CHARGEMENT ET PR√âPARATION DES DONN√âES
# ============================================================================
print("üìÇ √âtape 1: Chargement des donn√©es...")

df = pd.read_csv('server_usage_data.csv')
df = df.head(1440)

print(f"‚úÖ Donn√©es charg√©es: {len(df)} mesures sur 24h")
print(f"   P√©riode: {df['Time'].min()} ‚Üí {df['Time'].max()}")
print()

# ============================================================================
# 2. STATISTIQUES DESCRIPTIVES ET ROBUSTES
# ============================================================================
print("=" * 80)
print("üìä √âtape 2: STATISTIQUES DESCRIPTIVES ET ROBUSTES")
print("=" * 80)

metrics = ['CPU_Usage', 'Memory_Usage', 'Network_Usage', 'Temperature']
stats_results = pd.DataFrame()

for metric in metrics:
    values = df[metric]
    stats_results[metric] = {
        'Moyenne': values.mean(),
        'M√©diane': values.median(),
        '√âcart-type': values.std(),
        'Min': values.min(),
        'Max': values.max(),
        'Q1 (25%)': values.quantile(0.25),
        'Q3 (75%)': values.quantile(0.75),
        'IQR': values.quantile(0.75) - values.quantile(0.25),
        'CV (%)': (values.std() / values.mean()) * 100  # Coefficient de variation
    }

print("\nüìà Tableau des Statistiques:\n")
print(stats_results.round(2).T)
print("\nüí° Interpr√©tation:")
print("   - IQR (Interquartile Range): Mesure robuste de la dispersion")
print("   - CV (Coefficient de Variation): Dispersion relative (en %)")
print()

# ============================================================================
# 3. VISUALISATION DES DONN√âES
# ============================================================================
print("=" * 80)
print("üìâ √âtape 3: VISUALISATION DES M√âTRIQUES")
print("=" * 80)

fig, axes = plt.subplots(4, 1, figsize=(15, 12))
fig.suptitle('√âvolution des M√©triques sur 24h - Serveurs OPTIMAL',
             fontsize=16, fontweight='bold', y=0.995)

colors = ['#3b82f6', '#10b981', '#8b5cf6', '#ef4444']
titles = ['CPU Usage (%)', 'Memory Usage (Gb)', 'Network Usage (Mb/s)', 'Temperature (¬∞C)']
thresholds = [80, 12, 150, 70]

for i, (metric, color, title, threshold) in enumerate(zip(metrics, colors, titles, thresholds)):
    ax = axes[i]

    # Ligne principale
    ax.plot(df.index, df[metric], color=color, linewidth=1.5, alpha=0.8)

    # Moyenne
    mean_val = df[metric].mean()
    ax.axhline(mean_val, color=color, linestyle='--', linewidth=2,
               label=f'Moyenne: {mean_val:.2f}', alpha=0.7)

    # Seuil de vigilance
    ax.axhline(threshold, color='red', linestyle=':', linewidth=2,
               label=f'Seuil vigilance: {threshold}', alpha=0.7)

    # Zone de danger
    ax.fill_between(df.index, threshold, ax.get_ylim()[1],
                    color='red', alpha=0.1, label='Zone critique')

    ax.set_title(title, fontsize=12, fontweight='bold', pad=10)
    ax.set_xlabel('Minutes depuis 00:00' if i == 3 else '')
    ax.set_ylabel(title.split('(')[1].rstrip(')'))
    ax.legend(loc='upper right', fontsize=9)
    ax.grid(True, alpha=0.3)

    # Afficher les heures toutes les 2h
    if i == 3:
        tick_positions = range(0, 1440, 120)
        tick_labels = [f"{h:02d}:00" for h in range(0, 24, 2)]
        ax.set_xticks(tick_positions)
        ax.set_xticklabels(tick_labels, rotation=45)

plt.tight_layout()
plt.savefig('output/1_evolution_metriques.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique sauvegard√©: '1_evolution_metriques.png'")
plt.show()

# ============================================================================
# 4. DISTRIBUTIONS ET TESTS DE NORMALIT√â
# ============================================================================
print("\n" + "=" * 80)
print("üìä √âtape 4: ANALYSE DES DISTRIBUTIONS")
print("=" * 80)

fig, axes = plt.subplots(2, 4, figsize=(16, 8))
fig.suptitle('Distribution des M√©triques et Tests de Normalit√©',
             fontsize=16, fontweight='bold')

for i, (metric, color) in enumerate(zip(metrics, colors)):
    # Histogramme
    ax1 = axes[0, i]
    ax1.hist(df[metric], bins=30, color=color, alpha=0.7, edgecolor='black')
    ax1.axvline(df[metric].mean(), color='red', linestyle='--',
                linewidth=2, label='Moyenne')
    ax1.axvline(df[metric].median(), color='orange', linestyle='--',
                linewidth=2, label='M√©diane')
    ax1.set_title(metric.replace('_', ' '), fontweight='bold')
    ax1.set_xlabel('Valeur')
    ax1.set_ylabel('Fr√©quence')
    ax1.legend(fontsize=8)
    ax1.grid(True, alpha=0.3)

    # Q-Q Plot
    ax2 = axes[1, i]
    stats.probplot(df[metric], dist="norm", plot=ax2)
    ax2.set_title(f'Q-Q Plot', fontsize=10)
    ax2.grid(True, alpha=0.3)

    # Test de Shapiro-Wilk
    stat, p_value = stats.shapiro(df[metric].sample(min(5000, len(df))))
    normal = "‚úÖ Normale" if p_value > 0.05 else "‚ùå Non-normale"
    ax2.text(0.05, 0.95, f'p-value: {p_value:.4f}\n{normal}',
             transform=ax2.transAxes, fontsize=8,
             verticalalignment='top', bbox=dict(boxstyle='round',
                                                facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.savefig('output/2_distributions.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique sauvegard√©: '2_distributions.png'")
plt.show()

print("\nüìä Tests de Normalit√© (Shapiro-Wilk):")
for metric in metrics:
    stat, p_value = stats.shapiro(df[metric].sample(min(5000, len(df))))
    result = "NORMALE ‚úÖ" if p_value > 0.05 else "NON-NORMALE ‚ùå"
    print(f"   {metric:20s}: p-value = {p_value:.4f} ‚Üí {result}")

# ============================================================================
# 5. MATRICE DE CORR√âLATION
# ============================================================================
print("\n" + "=" * 80)
print("üîó √âtape 5: ANALYSE DES CORR√âLATIONS")
print("=" * 80)

correlation_matrix = df[metrics].corr()

print("\nüìä Matrice de Corr√©lation:\n")
print(correlation_matrix.round(3))

fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm',
            center=0.5, square=True, linewidths=2, cbar_kws={"shrink": 0.8},
            vmin=0, vmax=1, ax=ax)
ax.set_title('Matrice de Corr√©lation des M√©triques',
             fontsize=16, fontweight='bold', pad=20)
plt.tight_layout()
plt.savefig('output/3_correlation_matrix.png', dpi=300, bbox_inches='tight')
print("\n‚úÖ Graphique sauvegard√©: '3_correlation_matrix.png'")
plt.show()

print("\nüí° Corr√©lations Fortes (|r| > 0.7):")
for i, metric1 in enumerate(metrics):
    for j, metric2 in enumerate(metrics):
        if i < j:
            corr = correlation_matrix.loc[metric1, metric2]
            if abs(corr) > 0.7:
                sign = "positive" if corr > 0 else "n√©gative"
                print(f"   ‚Ä¢ {metric1} ‚Üî {metric2}: {corr:.3f} (corr√©lation {sign})")

# ============================================================================
# 6. D√âTECTION D'ANOMALIES
# ============================================================================
print("\n" + "=" * 80)
print("‚ö†Ô∏è  √âtape 6: D√âTECTION D'ANOMALIES")
print("=" * 80)

anomaly_results = {}

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('D√©tection d\'Anomalies - Z-Score et IQR',
             fontsize=16, fontweight='bold')
axes = axes.flatten()

for idx, (metric, color) in enumerate(zip(metrics, colors)):
    values = df[metric]

    # M√©thode Z-Score
    z_scores = np.abs(stats.zscore(values))
    z_anomalies = z_scores > 3

    # M√©thode IQR
    Q1 = values.quantile(0.25)
    Q3 = values.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    iqr_anomalies = (values < lower_bound) | (values > upper_bound)

    # Seuils de vigilance
    thresholds_dict = {'CPU_Usage': 80, 'Memory_Usage': 12,
                       'Network_Usage': 150, 'Temperature': 70}
    threshold = thresholds_dict[metric]
    threshold_exceeded = values > threshold

    anomaly_results[metric] = {
        'Z-Score (>3)': z_anomalies.sum(),
        'IQR': iqr_anomalies.sum(),
        f'Seuil >{threshold}': threshold_exceeded.sum(),
        'Pourcentage': (threshold_exceeded.sum() / len(df)) * 100
    }

    # Visualisation
    ax = axes[idx]
    ax.plot(df.index, values, color=color, alpha=0.6, linewidth=1)
    ax.scatter(df.index[z_anomalies], values[z_anomalies],
               color='red', s=50, label=f'Z-Score ({z_anomalies.sum()})',
               marker='o', alpha=0.8, edgecolors='darkred')
    ax.scatter(df.index[iqr_anomalies], values[iqr_anomalies],
               color='orange', s=30, label=f'IQR ({iqr_anomalies.sum()})',
               marker='s', alpha=0.8)
    ax.axhline(threshold, color='red', linestyle='--', linewidth=2,
               label=f'Seuil: {threshold}')
    ax.axhline(upper_bound, color='orange', linestyle=':', linewidth=1.5,
               label=f'IQR bounds', alpha=0.7)
    ax.axhline(lower_bound, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)

    ax.set_title(metric.replace('_', ' '), fontweight='bold')
    ax.set_xlabel('Minutes')
    ax.set_ylabel('Valeur')
    ax.legend(fontsize=8, loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('output/4_anomalies_detection.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique sauvegard√©: '4_anomalies_detection.png'")
plt.show()

print("\nüìä R√©sum√© des Anomalies D√©tect√©es:\n")
anomaly_df = pd.DataFrame(anomaly_results).T
print(anomaly_df.round(2))

# ============================================================================
# 7. MOD√àLES DE PR√âDICTION (R√âGRESSION LIN√âAIRE)
# ============================================================================
print("\n" + "=" * 80)
print("üîÆ √âtape 7: MOD√àLES DE PR√âDICTION")
print("=" * 80)

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Pr√©dictions avec R√©gression Lin√©aire',
             fontsize=16, fontweight='bold')
axes = axes.flatten()

prediction_results = {}

for idx, (metric, color) in enumerate(zip(metrics, colors)):
    X = np.arange(len(df)).reshape(-1, 1)
    y = df[metric].values

    # Mod√®le de r√©gression
    model = LinearRegression()
    model.fit(X, y)

    # Pr√©dictions actuelles et futures
    X_future = np.arange(len(df) + 60).reshape(-1, 1)
    y_pred = model.predict(X_future)

    # M√©triques
    r2_score = model.score(X, y)
    slope = model.coef_[0]
    intercept = model.intercept_

    if abs(slope) > 0.01:
        trend = "Hausse" if slope > 0 else "Baisse"
    else:
        trend = "Stable"

    prediction_results[metric] = {
        'Pente': slope,
        'Ordonn√©e': intercept,
        'R¬≤': r2_score,
        'Tendance': trend
    }

    # Visualisation
    ax = axes[idx]
    ax.scatter(X, y, alpha=0.3, s=10, color=color, label='Donn√©es r√©elles')
    ax.plot(X, model.predict(X), color='red', linewidth=2,
            label='R√©gression lin√©aire')
    ax.plot(X_future[-60:], y_pred[-60:], color='orange', linewidth=2,
            linestyle='--', label='Pr√©diction 60 min')
    ax.axvline(len(df), color='green', linestyle=':', linewidth=2,
               label='Limite actuelle')

    ax.set_title(f"{metric.replace('_', ' ')} - {trend}", fontweight='bold')
    ax.set_xlabel('Minutes')
    ax.set_ylabel('Valeur')
    ax.legend(fontsize=8)
    ax.grid(True, alpha=0.3)

    # Annotation
    textstr = f'y = {slope:.4f}x + {intercept:.2f}\nR¬≤ = {r2_score:.4f}'
    ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=9,
            verticalalignment='top', bbox=dict(boxstyle='round',
                                               facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.savefig('output/5_predictions_regression.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique sauvegard√©: '5_predictions_regression.png'")
plt.show()

print("\nüìä R√©sultats des Mod√®les de Pr√©diction:\n")
pred_df = pd.DataFrame(prediction_results).T
print(pred_df.round(4))

# ============================================================================
# 8. ANALYSE DES PATTERNS TEMPORELS
# ============================================================================
print("\n" + "=" * 80)
print("‚è∞ √âtape 8: ANALYSE DES PATTERNS TEMPORELS")
print("=" * 80)


df['Time'] = pd.to_datetime(df['Time'], errors='coerce')
df['Hour'] = df['Time'].dt.hour
hourly_stats = df.groupby('Hour')[metrics].agg(['mean', 'std', 'max'])

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Patterns Temporels - Analyse par Heure',
             fontsize=16, fontweight='bold')
axes = axes.flatten()

for idx, (metric, color) in enumerate(zip(metrics, colors)):
    ax = axes[idx]
    hours = range(24)
    means = hourly_stats[metric]['mean']
    stds = hourly_stats[metric]['std']
    maxs = hourly_stats[metric]['max']

    ax.plot(hours, means, color=color, linewidth=3, marker='o',
            markersize=8, label='Moyenne')
    ax.fill_between(hours, means - stds, means + stds,
                    color=color, alpha=0.2, label='¬±1 √©cart-type')
    ax.plot(hours, maxs, color='red', linewidth=2, linestyle='--',
            marker='s', markersize=6, label='Maximum', alpha=0.7)

    # Identifier les heures de pic
    peak_hour = means.idxmax()
    peak_value = means.max()
    ax.axvline(peak_hour, color='red', linestyle=':', alpha=0.5)
    ax.text(peak_hour, peak_value, f'Pic: {peak_hour}h',
            fontsize=9, ha='center', bbox=dict(boxstyle='round',
                                               facecolor='yellow', alpha=0.5))

    ax.set_title(metric.replace('_', ' '), fontweight='bold')
    ax.set_xlabel('Heure de la journ√©e')
    ax.set_ylabel('Valeur')
    ax.set_xticks(range(0, 24, 2))
    ax.legend(fontsize=8)
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('output/6_temporal_patterns.png', dpi=300, bbox_inches='tight')
print("‚úÖ Graphique sauvegard√©: '6_temporal_patterns.png'")
plt.show()

print("\nüìä Heures de Pic Identifi√©es:")
for metric in metrics:
    peak_hour = hourly_stats[metric]['mean'].idxmax()
    peak_value = hourly_stats[metric]['mean'].max()
    print(f"   ‚Ä¢ {metric:20s}: {peak_hour:02d}:00 ({peak_value:.2f})")

# ============================================================================
# 9. EXPORT DES R√âSULTATS
# ============================================================================
print("\nüìÅ √âtape 10: Export des r√©sultats...")

# Sauvegarder les statistiques
stats_results.T.to_csv('output/resultats_statistiques.csv')
print("‚úÖ Statistiques export√©es: 'resultats_statistiques.csv'")

# Sauvegarder les anomalies
anomaly_df.to_csv('output/resultats_anomalies.csv')
print("‚úÖ Anomalies export√©es: 'resultats_anomalies.csv'")

# Sauvegarder la matrice de corr√©lation
correlation_matrix.to_csv('output/matrice_correlation.csv')
print("‚úÖ Corr√©lations export√©es: 'matrice_correlation.csv'")

print("\n" + "=" * 80)
print("üéâ ANALYSE TERMIN√âE AVEC SUCC√àS!")
print("=" * 80)
print("üìä 6 graphiques g√©n√©r√©s")
print("üìÅ 3 fichiers CSV export√©s")
print("=" * 80)